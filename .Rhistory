source('~/Downloads/workshop_Rmd-master/your_script.R')
source('~/Downloads/workshop_Rmd-master/your_script.R')
source('~/Downloads/workshop_Rmd-master/your_script.R', echo=TRUE)
source('~/Downloads/workshop_Rmd-master/your_script.R')
require(devtools)
install_github('rCharts', 'ramnathv')
install.packages(c("googleVis"))
library(sp)
??write.ascii
library(rgdal)
>>write.ascii
write.ascii
write.asci
??write.ascii
library(raster)
??write.ascii
library(rgeos)
??write.ascii
library(maptools)
??write.ascii
?write.ascii
help(write.ascii)
help(raster)
??write.csv
getpwd()
getwd()
#output: ioslides_presentation
dir()
x <- c(4, TRUE)?
)
x <- c(4, TRUE)
class(x)
x
x <- c("a","b")
class(x)
library(historydata)
objects()
data(paulist_missions)
objects()
paulist_missions
head(paulist_missions)
dim(paulist_missions)
length(unique(church))
length(unique(paulist_missions$church))
head(unique(paulist_missions$church))
head(paulist_missions[paulist_missions$church == "St. Mary's Church",])
paulist_missions[paulist_missions$church == "St. Mary's Church",]
paulist_missions[paulist_missions$church == "St. Mary's Church",]
write.csv(paulist_missions,file="/Users/patty/Documents/Dlab/dhsi/work/paulist_church.csv",row.names=F)
write.csv(paulist_missions,file="/Users/patty/Documents/Dlab/dhsi/work/paulist_church.csv",row.names=F,na.rm=T)
write.csv(paulist_missions,file="/Users/patty/Documents/Dlab/dhsi/work/paulist_church.csv",row.names=F)
write.csv(paulist_missions,file="/Users/patty/Documents/Dlab/dhsi/work/NHGIS/paulist_church.csv",row.names=F)
suppressPackageStartupMessages(library(googleVis))
op <- options(gvis.plot.tag='chart')
op
Pie <- gvisPieChart(CityPopularity, options = list(width=400, height=400))
plot(Pie)
plot(Pie)
install.packages("shiny")
library(shiny)
library(leaflet)
library(RColorBrewer)
library(rgdal)
library(raster)
library(ggmap)
###Load and clean data
source("loadData.R")
###GGPLOT
#MAP 1: map with ggplot
map <- ggplot() +
geom_point(data=berkeleyCrime, aes(x=long, y=lat))
map
#MAP 2: adding a background map using ggmap
background <- get_map(location=c(lon = mean(berkeleyCrime$long),
lat = mean(berkeleyCrime$lat)),
zoom=14,
maptype = "terrain",
source="google",
color="bw")
#EXPLORE: change maptype from "terrain" to "satellite".
#EXPLORE: change color from "bw" to "color".
#EXPLORE MORE: In the console, type ?get_map to view other options to customize your background map
map <- ggmap(background) + coord_equal() +
geom_point(data=berkeleyCrime, aes(x=long, y=lat, alpha=0.3, size=7, color=CVLEGEND)) +
scale_size_continuous(range = c(3), guide=FALSE) +
scale_alpha_continuous(range = c(.3), guide=FALSE)
map
##MAP 3: map data with Leaflet.js
leaflet(berkeleyCrime) %>%
addProviderTiles("CartoDB.Positron") %>%
#EXPLORE: Change 'CartoDB.Positron' to 'Esri.WorldImagery' or one of the other
#provider tiles available at http://leaflet-extras.github.io/leaflet-providers/preview/
addCircleMarkers(
stroke = FALSE, fillOpacity = 0.5, radius=4,
popup = ~paste("<strong>Offense:</strong>",OFFENSE)
) #%>% addMarkers(lng=-122.2579, lat=37.87004, popup="Barrows Hall")
#EXPLORE: uncomment previous line to add a marker on top of Barrows Hall
#EXPLORE MORE: run ?addControl to view all of the different layers you can add to Leaflet
## QUESTION  - how to add polygons??
help()
# Get a distance matrix from Google's Distance Matrix API
# https://developers.google.com/maps/documentation/distancematrix/
library(httr)
# Five most populous US cities in 2012
# http://en.wikipedia.org/wiki/List_of_United_States_cities_by_population
cities <- "New+York+NY|Los+Angeles+CA|Chicago+IL|Houston+TX|Philadelphia+PA"
# Request object from API
r <- GET(
"http://maps.googleapis.com/maps/api/distancematrix/json",
query = list(
origins = cities,
destinations = cities,
sensor = "false")
)
stop_for_status(r)
distances <- content(r)
m <- matrix(nrow = 5, ncol = 5)
rownames(m) <- unlist(distances$destination_addresses)
colnames(m) <- unlist(distances$origin_addresses)
# I'm sure there's a more idiomatic way
for (i in 1:length(distances$rows)) {
for (j in 1:length(distances$rows[[i]]$elements)) {
m[i,j] <- distances$rows[[i]]$elements[[j]]$distance$value
}
}
m
r
distances
distances$destination_addresses
unlist(distances$destination_addresses)
getTheDist <- function(mystart,myend) {
r <- GET(
"http://maps.googleapis.com/maps/api/distancematrix/json",
query = list(
origins = mystart,
destinations = myend,
sensor = "false")
)
return r
}
getTheDist <- function(mystart,myend) {
r <- GET(
"http://maps.googleapis.com/maps/api/distancematrix/json",
query = list(
origins = mystart,
destinations = myend,
sensor = "false")
)
return r
}
getTheDist <- function(mystart,myend) {
r <- GET(
"http://maps.googleapis.com/maps/api/distancematrix/json",
query = list(
origins = mystart,
destinations = myend,
sensor = "false")
)
return(r)
}
getTheDist("New+York+NY","Los+Angeles+CA")
x <-getTheDist("New+York+NY","Los+Angeles+CA")
x
x$rows$elements$distance$text
x$rows$elements$distance$value
x$rows[0]$elements[0]$distance$value
class(x)
type(x)
x$url
str(x)
x <-content(getTheDist("New+York+NY","Los+Angeles+CA"))
x
x$rows[1]$elements[1]$distance$value
x$rows$elements$distance$value
x$rows[[1]]$elements[[1]$distance$value
x$rows[[1]]$elements[[1]]$distance$value
getTheDist <- function(mystart,myend) {
r <- GET(
"http://maps.googleapis.com/maps/api/distancematrix/json",
query = list(
origins = mystart,
destinations = myend,
sensor = "false")
)
x<- content(r)
return( x$rows[[1]]$elements[[1]]$distance$value)
}
getTheDist("New+York+NY","Los+Angeles+CA")
getTheDistMeters <- function(mystart,myend) {
r <- GET(
"http://maps.googleapis.com/maps/api/distancematrix/json",
query = list(
origins = mystart,
destinations = myend,
sensor = "false")
)
#stop_for_status(r)
distmatrix_result <- content(r)
return( distmatrix_result$rows[[1]]$elements[[1]]$distance$value)
}
getTheDist("New+York+NY","Los+Angeles+CA")
getTheDist("37.8719034,-122.2607286","37.757815,-122.5076406")
getTheDist("37.8719034,-122.2607286","37.757815,-122.5076406") /1000
getTheDist(37.8719034,-122.2607286,37.757815,-122.5076406) /1000
x
getGoogleDistance <- function(mystart,myend,outval="the_distmeters") {
r <- GET(
"http://maps.googleapis.com/maps/api/distancematrix/json",
query = list(
origins = mystart,
destinations = myend,
sensor = "false")
)
#stop_for_status(r)
distmatrix_result <- content(r)
if (outval == 'the_distmeters'){
return( distmatrix_result$rows[[1]]$elements[[1]]$distance$value)
} else {
return( distmatrix_result$$rows[[1]]$elements[[1]]$duration$text)
}
}
getGoogleDistance <- function(mystart,myend,outval="the_distmeters") {
r <- GET(
"http://maps.googleapis.com/maps/api/distancematrix/json",
query = list(
origins = mystart,
destinations = myend,
sensor = "false")
)
#stop_for_status(r)
distmatrix_result <- content(r)
if (outval == 'the_distmeters') {
return( distmatrix_result$rows[[1]]$elements[[1]]$distance$value)
} else {
return( distmatrix_result$$rows[[1]]$elements[[1]]$duration$text)
}
}
getGoogleDistance <- function(mystart,myend, outval="the_distmeters") {
r <- GET(
"http://maps.googleapis.com/maps/api/distancematrix/json",
query = list(
origins = mystart,
destinations = myend,
sensor = "false")
)
#stop_for_status(r)
distmatrix_result <- content(r)
if (outval == 'the_distmeters') {
return( distmatrix_result$rows[[1]]$elements[[1]]$distance$value)
} else {
return( distmatrix_result$rows[[1]]$elements[[1]]$duration$text )
}
}
getGoogleDistance("New+York+NY","Los+Angeles+CA")
getGoogleDistance("37.8719034,-122.2607286","37.757815,-122.5076406") /1000 #in Kilometers
getGoogleDistance("37.8719034,-122.2607286","37.757815,-122.5076406","the_time") # in meters
getGoogleDistance <- function(mystart,myend, outval="the_distmeters") {
r <- GET(
"http://maps.googleapis.com/maps/api/distancematrix/json",
query = list(
origins = mystart,
destinations = myend,
sensor = "false")
)
#stop_for_status(r)
distmatrix_result <- content(r)
if (outval == 'the_distmeters') {
return( distmatrix_result$rows[[1]]$elements[[1]]$distance$value)
} else {
return( distmatrix_result$rows[[1]]$elements[[1]]$duration$value )
}
}
getGoogleDistance("37.8719034,-122.2607286","37.757815,-122.5076406","the_time")
2949/60
getGoogleDistance("37.8719034,-122.2607286","37.757815,-122.5076406","the_time") /60 # in min
my_cities <- read.csv("/Users/patty/Documents/Dlab/dlab_workshops/geocoding/geocoding_sp2016/dist_matrix_sample_data - Sheet1.csv")
my_cities
my_cities$start_lat
my_cities$start_lat[1]
my_cities$start_lat[2]
my_cities$start_coords[2]
my_cities$end_coords[2]
my_cities <- read.csv("/Users/patty/Documents/Dlab/dlab_workshops/geocoding/geocoding_sp2016/dist_matrix_sample_data - Sheet1.csv", stringsAsFactors = False)
my_cities$end_coords[2]
my_cities <- read.csv("/Users/patty/Documents/Dlab/dlab_workshops/geocoding/geocoding_sp2016/dist_matrix_sample_data - Sheet1.csv", stringsAsFactors = FALSE)
my_cities$end_coords[2]
getGoogleDistance(my_cities$start_coords,my_cities$end_coords,"the_time") /60 # in min
getGoogleDistance(my_cities$start_coords,my_cities$end_coords,"the_time")
getGoogleDistance(my_cities$start_coords[1],my_cities$end_coords[1],"the_time")
my_cities$start_coords[1]
my_cities <- read.csv("/Users/patty/Documents/Dlab/dlab_workshops/geocoding/geocoding_sp2016/dist_matrix_sample_data.csv", stringsAsFactors = FALSE)
my_cities$start_coords[1]
getGoogleDistance(my_cities$start_coords[1],my_cities$end_coords[1],"the_time")
getGoogleDistance(my_cities$start_coords[1],my_cities$end_coords[1],"the_time")
mutate(my_cities, the_dist= getGoogleDistance(start_coords,end_coords))
(dplyr)
mutate(my_cities, the_dist= getGoogleDistance(start_coords,end_coords))
library(plyr)
mdply(my_cities, the_dist= getGoogleDistance(start_coords,end_coords))
mdply(my_cities, the_dist=getGoogleDistance(start_coords,end_coords))
mutate(my_cities,the_dist=getGoogleDistance(start_coords,end_coords))
my_cities <- mutate(my_cities,the_dist=getGoogleDistance(start_coords,end_coords))
my_cities
my_cities$the_dist
my_cities$start_coords[1]
the_dist
getGoogleDistance(my_cities$start_coords,my_cities$end_coords)
getGoogleDistance(my_cities$start_coords,my_cities$end_coords,"the_dist")
getGoogleDistance(my_cities$start_coords[1],my_cities$end_coords[1],"the_time")
getGoogleDistance(my_cities$start_coords[1],my_cities$end_coords[1],"the_distmeters")
getGoogleDistance(my_cities$start_coords[1],my_cities$end_coords[1])
getGoogleDistance(my_cities$start_coords[1],my_cities$end_coords[1])
mutate(my_cities,the_dist=getGoogleDistance(start_coords,end_coords))
mutate(my_cities,the_dist=getGoogleDistance(start_coords[1],end_coords[1]))
myf <- function(tens, ones) { 10 * tens + ones }
x <- data.frame(hundreds = 7:9, tens = 1:3, ones = 4:6)
x
mutate(x, value = myf(tens, ones))
mutate(my_cities, the_dist = getGoogleDistance(start_coords,end_coords))
mutate(x, value = myf(tens, ones))
mutate(my_cities, the_dist2 = getGoogleDistance(start_coords,end_coords))
mapply(getGoogleDistance, my_cities[, "start_coords"], my_cities[, "end_coords"])
my_cities$dist1 <- mapply(getGoogleDistance, my_cities[, "start_coords"], my_cities[, "end_coords"])
my_cities
my_cities$the_dist_meters <- mapply(getGoogleDistance, my_cities[, "start_coords"], my_cities[, "end_coords"])
my_cities$travel_time_secs <- mapply(getGoogleDistance, my_cities[, "start_coords"], my_cities[, "end_coords"],"the_time")
my_cities
my_cities$the_dist_km <- mapply(getGoogleDistance, my_cities[, "start_coords"], my_cities[, "end_coords"]) /1000
my_cities$travel_time_min <- mapply(getGoogleDistance, my_cities[, "start_coords"], my_cities[, "end_coords"],"the_time") /60
my_cities
# Read in file of lat/lons
# get distances
my_cities <- read.csv("/Users/patty/Documents/Dlab/dlab_workshops/geocoding/geocoding_sp2016/dist_matrix_sample_data.csv", stringsAsFactors = FALSE)
getGoogleDistance(my_cities$start_coords[1],my_cities$end_coords[1],"the_time")
#Apply to entire table
my_cities$the_dist_km <- mapply(getGoogleDistance, my_cities[, "start_coords"], my_cities[, "end_coords"]) / 1000
my_cities$travel_time_min <- mapply(getGoogleDistance, my_cities[, "start_coords"], my_cities[, "end_coords"],"the_time") / 60
my_cities
#------------------------------------------------------------------------------------
# timeseries_webmaps.R
#------------------------------------------------------------------------------------
# This script creates time series animated and interactive webmaps
# from data in an excel spreadsheet using a customized version of the rMaps package.
#
# pattyf@berkeley.edu, June 2016
#
#------------------------------------------------------------------------------------
#-------------------
# Clear workspace
#-------------------
rm(list=ls())
#--------------------------------------------------------------------------
# Set Important Parameters
# THESE SHOULD BE THE ONLY VALUES YOU NEED TO CHANGE to run this script
#--------------------------------------------------------------------------
my_tmp_download_directory <- "/Users/patty/Downloads"
my_data_directory <- "~/Documents/Dlab/consults/robin_e/1june2016"
update_local_version_of_RMaps = "no" # Set to "yes" if Patty has made changes
in_data_file <- "SOI data all Returns Map Input2.xlsx"    # The name of the input MS Excel file
in_data_worksheet <- 1  # The excel worksheet with the data, default is the first sheet
start_year <- "1916"    # The first year column in the input excel file
end_year <- "2011"      # The last year column in the input excel file
out_data_file <-'soi_returns_per1k_long.csv'   # The name of the output CSV file that this script will create
# It will contain the data values that will be mapped
out_map_file <- "ic3.html"    # The name of the output file that will contain the map
map_title = "SOI Returns Per 1000, Percent of National Avg, "  # The title along the top of the map
data_label_in_popup = "Percent National Avg: "                 # When you click over the state you get a popup box
# that displays the state name, year, and data value.
# This is the name for the data value that will display in popup
num_decimal_places = 1  # The number of decimal places to use for the mapped data
map_breaks <- c(1,50,75,90,110,125,150)  # The breakpoints for map colors
# Note: the first number and last numbers are inclusive.
# Once the data is read into R, the maximum data value is appended to the map_breaks
# Color palettes
# To see the names of the different palettes you can try see:
# https://github.com/dlab-geo/rMaps/raw/master/data/r_color_palettes.pdf
#
map_color_palette <- "PuOr" # The name of the color palette that will be used.
map_nodata_color <- "#FFFFFF" # The color to use for no data values (values not included in the breaks, eg zero)
map_nodata_label <- "[0]"
show_map_legend <- TRUE     # set to TRUE or FALSE - no quotes
show_map_labels <- TRUE    # set to TRUE or FALSE - no quotes
#--------------------------------------------------------------------------
# END OF THINGS THAT NEED TO CHANGE!!
#--------------------------------------------------------------------------
#-----------------------------
# INSTALL REQUIRED R PACKAGES
#-----------------------------
# Install helper packages
required.pkg <- c('tidyr','dplyr','readxl','devtools','downloader')
pkgs.not.installed <- required.pkg[!sapply(required.pkg, function(p) require(p, character.only=T))]
if (length(pkgs.not.installed > 0)) {
install.packages(pkgs.not.installed, dependencies=TRUE)
} else {
print("Helper packages installed.")
}
# Install rMaps and rCharts packages for creating the map
if ("rMaps" %in% rownames(installed.packages()) == FALSE ) {
require(devtools)
install_github('ramnathv/rCharts@dev')
install_github('ramnathv/rMaps')
} else {
print("Rmaps installed.")
}
# -----------------------------------------------------------------------------------
# IMPORTANT: Update local version of the rMaps package
# Do whenever patty makes an update to it
# Just set 'update_local_version_of_RMaps' to 'yes'
# NOTES:
# 1. update the download directory specified below
# 2. YOU MUST RESTART R Session or RStudio after re-installing!!!
# 3. Set 'Update_local_version_of_RMaps' to 'no'
# -----------------------------------------------------------------------------------
# -----------------------------------------------------------------------------------
### Load Libraries
library(reshape2)
library(rMaps)
library(plyr)
library(tidyr)
library(dplyr)
library(readxl)
library(rCharts)
library(RColorBrewer)
require(devtools)
install_github('ramnathv/rCharts@dev')
install_github('ramnathv/rMaps')
library(readxl)
version
Sys.info()
sessionInfo()
?sessionInfo
#clean environment
rm(list=ls())
#set working directory
setwd("~/Documents/Dlab/dlab_workshops/rgeocoding")
library(sp)
library(rgdal)
library(rgeos)
# read in geocoded addresses
geocoded_output_file <- "geocoded_addresses_out.csv"
geocoded_results <- read.csv(geocoded_output_file,stringsAsFactors = FALSE)
head(geocoded_results) # take a look at the results
coordinates(geocoded_results) <- ~lon+lat
plot(geocoded_results)
geocoded_results@proj4string # undefined
proj4string(geocoded_results) <- CRS(proj4string(alameda_ccds))
# Read downloaded shapefile into R
alameda_ccds <- readOGR(dsn="./shapefiles/AlamedaCommunityCollegeDistricts", layer="geo_export_ffa93779-e8e7-4680-a57c-75b25ae5830c")
class(alameda_ccds) # what is the data object type?
plot(alameda_ccds)  #plot the CCDs
points(geocoded_results, col="red") # add the geocoded points to the plot
proj4string(geocoded_results) <- CRS(proj4string(alameda_ccds))
proj4string(alameda_ccds) == proj4string(geocoded_results)
geocoded_results@proj4string
library(sp)
pts_web <- spTransform(geocoded_results, CRS("+init=epsg:3857"))
pts_web
